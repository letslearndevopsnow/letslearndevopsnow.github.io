---
layout:     post
title:      "Hpa & Vpa"
subtitle:   "Horizontal Pod Autoscaling & Vertical Pod Autoscaling In Kubernetes"
date:       2021-07-15 17:00:00
author:     "Thaung Htike Oo"
header-img: img/black.jpg
catalog: true
tags:
    - Kubernetes
---

<h2> Horizontal Pod Autoscaling & Vertical Pod Autoscaling </h2>

ကျွန်တော်ဒီနေ့ ရေးမယ့်အကြောင်းအရာကတော့ kubernetes ပေါ်မှာရှိတဲ့ pod တွေကို autoscaling လုပ်နည်းပဲဖြစ်ပါတယ်။ ကျွန်တော်တို့ production အတွက် deployment တွေ လုပ်တဲ့အခါ pod template ထဲမှာ resources အ
တွက် cpu နဲ့ memory တွေကို request ၊ limit ပမာဏတွေသတ်မှတ်ပေးပြီး resource quota တွေကိုကန့်သတ်ပေးထားပါတယ်။ အဲ့ဒီအခါမှသာ pod တစ်ခုထဲက node ရဲ့ cpu memory resource တွေကို သူတစ်ခုထဲအတွက် သုံးတာကို 
ကာကွယ်နိုင်ပါမယ်။ pod တွေ deployment တွေ create တဲ့အခါ quota မှာ request ဆိုတာက သတ်မှတ်ထားတဲ့ amount ကိုပေးနိုင်တဲ့ node အပေါ်မှာသာ pod တွေကို deploy လုပ်ပေးမှာဖြစ်ပြီး limit က အဲ့ amount အထိသာ 
pod အတွက် resource ကိုပေးသုံးမှာဖြစ်ပါတယ်။

<h2> Prequities </h2>

```bash
kubernetes cluster
````
<h2> Prepare A Kubernetes Cluster </h2>

autoscaling တွေစမ်းဖို့အတွက် kubernetes cluster တစ်ခု create ပေးရပါမယ်။ ကျွန်တော်ကတော့ aks cluster တစ်ခု create လုပ်လိုက်ပါမယ်။ 

```bash
az group create --name kube --location eastus
az aks create --name demo -g kube --location eastus --node-count 2
az aks get-credentials --name demo -g kube
```
ပြီးသွားရင်တော့ kubectl get nodes နဲ့ကြည့်လိုက်ပါမယ်။ node တွေ ready ဖြစ်နေရင် autoscaling အကြောင်းကို စစမ်းလို့ရပါပြီ။

```bash
thaunghtikeoo@thaunghtikeoo:~$ kubectl get nodes 
NAME                                STATUS    ROLES     AGE       VERSION
aks-nodepool1-23943392-vmss000000   Ready     agent     100s      v1.19.11
aks-nodepool1-23943392-vmss000001   Ready     agent     99s       v1.19.11
```
<h2> Horizontal Pod Autoscaling </h2>

HPA ဆိုတာက pod တွေရဲ့ replicas အရေအတွက်ကို autoscale လုပ်ပေးတာဖြစ်ပါတယ်။ ကျွန်တော်တို့သတ်မှတ်ခဲ့တဲ့ resource quota ရဲ့ request cpu ၊ memory utilization တွေအပေါ်မူတည်ပြီး pods တွေကို scale in ၊ scale out 
လုပ်ပေးတာဖြစ်ပါတယ်။ အရင်ဆုံး pod တွေ nodes တွေရဲ့ resource utilization ကိုသိဖို့ဆို metric-server ကို deploy လုပ်ပေးရပါမယ်။ aks မှာတော့ defautl သွင်းထားပြီးသားဖြစ်ပါတယ်။

```bash
thaunghtikeoo@thaunghtikeoo:~$ kubectl get pods --all-namespaces
NAMESPACE     NAME                                  READY     STATUS    RESTARTS   AGE
kube-system   azure-ip-masq-agent-7rhvx             1/1       Running   0          12m
kube-system   azure-ip-masq-agent-xjcsb             1/1       Running   0          12m
kube-system   coredns-76c97c8599-fgqfj              1/1       Running   0          12m
kube-system   coredns-76c97c8599-qr92j              1/1       Running   0          13m
kube-system   coredns-autoscaler-599949fd86-45twt   1/1       Running   0          13m
kube-system   kube-proxy-ljdnx                      1/1       Running   0          12m
kube-system   kube-proxy-wp6b7                      1/1       Running   0          12m
kube-system   metrics-server-77c8679d7d-vk8n8       1/1       Running   0          13m
kube-system   tunnelfront-544cd5b988-cshrh          1/1       Running   0          13m
```
HPA ကို စမ်းဖို့ဆို autoscale လုပ်ချင်တဲ့ deployment ကို resource quota တွေသတ်မှတ်ပေးဖို့လိုပါတယ်။ ပထမဆုံးအနေနဲ့ demo ဆိုတော့ nginx deployment တစ်ခုနဲ့ပဲစမ်းကြည့်ကြမယ်။ ဘာ deployment မှမလုပ်ခင် nodes တွေရဲ့
cpu memory usage ပဲဖြစ်ပါတယ်။

```bash
thaunghtikeoo@thaunghtikeoo:~$ kubectl top nodes
NAME                                CPU(cores)   CPU%      MEMORY(bytes)   MEMORY%   
aks-nodepool1-23943392-vmss000000   50m          2%        673Mi           14%       
aks-nodepool1-23943392-vmss000001   129m         6%        651Mi           14%      
```
nginx deployment တစ်ခုကို create ပါမယ်။ cpu 250m ကို request ထားပြီး 500m အထိ limit ပေးထားပါတယ်။ ပြီးရင် kubectl create နဲ့ deployment ကို create လိုက်ပါ။ 

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  labels:
    run: nginx
  name: nginx
spec:
  replicas: 1
  selector:
    matchLabels:
      run: nginx
  template:
    metadata:
      labels:
        run: nginx
    spec:
      containers:
      - image: nginx
        name: nginx
        ports:
        - containerPort: 80
        resources:
          requests:
            cpu: 250m
          limits:
            cpu: 500m  
```
ပြီးရင်တော့ defautl namespace မှာ nginx deployment တစ်ခု run နေတာကိုတွေ့ရမှာဖြစ်ပါတယ်။ 

```bash
haunghtikeoo@thaunghtikeoo:~$ kubectl get all 
NAME                        READY     STATUS    RESTARTS   AGE
pod/nginx-fdb6cfbc5-fwggl   1/1       Running   0          32s

NAME                 TYPE        CLUSTER-IP   EXTERNAL-IP   PORT(S)   AGE
service/kubernetes   ClusterIP   10.0.0.1     <none>        443/TCP   29m

NAME                    READY     UP-TO-DATE   AVAILABLE   AGE
deployment.apps/nginx   1/1       1            1           33s

NAME                              DESIRED   CURRENT   READY     AGE
replicaset.apps/nginx-fdb6cfbc5   1         1         1         34s
```
အခုချိန်မှာ pod ရဲ့ cpu usage က 0% ဖြစ်နေပါတယ်။ ဒါဆိုအခု hpa ကိုစစမ်းကြည့်ပါမယ်။ အောက်က yaml file ကိုကြည့်ပါ။ request ထားတဲ့ 250m ရဲ့ 50% အထိ pod က cpu utilization တက်လာတဲ့အခါ pod ကို maximum
5 ခုအထိ scale out လုပ်မှာဖြစ်ပြီး cpu usage ပြန်ကျသွားရင်တော့ minimun 1 ခုအဖြစ်ပြန် scale in လုပ်လိုက်မှာဖြစ်ပါတယ်။

```yaml
apiVersion: autoscaling/v1
kind: HorizontalPodAutoscaler
metadata:
  name: nginx
spec:
  maxReplicas: 5
  minReplicas: 1
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: nginx
  targetCPUUtilizationPercentage: 50
```
kubectl apply နဲ့ create လိုက်ပါမယ်။ အခုချိန်မှာ cpu က သုညပဲဖြစ်နေပါသေးတယ်။ 

```yaml
thaunghtikeoo@thaunghtikeoo:~$ kubectl get hpa
NAME      REFERENCE          TARGETS   MINPODS   MAXPODS   REPLICAS   AGE
nginx     Deployment/nginx   0%/50%    1         5         1          2m44s
```
ကျွန်တော်တို့ nginx service ကို အပြင်ကခေါ်လို့ရအောင် loadbalancer အနေနဲ့ expose လိုက်ပါမယ်။

```bash
kubectl expose deploy nginx --type LoadBalancer --target-port 80 --port 80

thaunghtikeoo@thaunghtikeoo:~$ kubectl get svc
NAME         TYPE           CLUSTER-IP    EXTERNAL-IP    PORT(S)        AGE
kubernetes   ClusterIP      10.0.0.1      <none>         443/TCP        40m
nginx        LoadBalancer   10.0.36.206   20.72.185.88   80:31934/TCP   7s
```
ပြီးသွားရင်တော့ cpu overload ဖြစ်အောင် test ဖို့အတွက် siege tool ကို install ပေးရပါမယ်။ 

```yaml
apt update -y && apt install siege -y
```
ဒါဆိုရင်ကျွန်တော်တို့ nginx deployment က pods တွေကို cpu usage တက်လာအောင် အောက်ကအတိုင်းစမ်းပါမယ်။ nginx service url ကို 2 minute အထိ cpu တက်အောင်လုပ်လိုက်ပါမယ်။

```bash
siege -q -c 5 -t 2m 20.72.185.88
```
ခဏကြာတော့ cpu load ဖြစ်လာပြီး hpa မှာ percent တွေတက်လာပြီး replicas တွေ scale out ဖြစ်လာပါပြီ။

```bash
thaunghtikeoo@thaunghtikeoo:~$ kubectl get hpa
NAME      REFERENCE          TARGETS    MINPODS   MAXPODS   REPLICAS   AGE
nginx     Deployment/nginx   110%/50%   1         5         4          2m14s
```
အသစ်ထွက်လာတဲ့ pods တွေကလည်းတစ်ခုပြီး တစ်ခု CPU usage တွေတက်လာပြီး နောက်ဆုံးမှာ maximum သတ်မှတ်ခဲ့တဲ့ 5 ခုအထိ တိုးသွားပါတယ်။ 

```bash
thaunghtikeoo@thaunghtikeoo:~$ kubectl get pods
NAME                    READY     STATUS    RESTARTS   AGE
nginx-fdb6cfbc5-2dvxg   1/1       Running   0          6m55s
nginx-fdb6cfbc5-9cjn7   1/1       Running   0          16s
nginx-fdb6cfbc5-h8h85   1/1       Running   0          16s
nginx-fdb6cfbc5-lmfdw   1/1       Running   0          16s
nginx-fdb6cfbc5-8cvtq   1/1       Running   0          16s
```

```bash
thaunghtikeoo@thaunghtikeoo:~$ kubectl top pods
NAME                    CPU(cores)   MEMORY(bytes)   
nginx-fdb6cfbc5-2dvxg   0m           11Mi            
nginx-fdb6cfbc5-8cvtq   0m           9Mi             
nginx-fdb6cfbc5-9cjn7   0m           10Mi            
nginx-fdb6cfbc5-h8h85   0m           9Mi             
nginx-fdb6cfbc5-lmfdw   0m           10Mi      
```
